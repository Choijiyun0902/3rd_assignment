지도 학습 vs 비지도 학습

지도 – 정답 존재 -> 기출 문제 푸는 시험 준비 방식과 유사

회귀 vs 분류

분류 – classifi – 이산 – 이산적인 클래스 값, 확률을 계산하여 예측 (시그모이드 함수)
회귀 – regress – 연속 – 예측과 실제의 차를 최소화하는 것이 관건/실수 값의 형태

회귀와 분류는 서로 상호적인 관계

회귀 – Linear Regression, Polynomial, 릿지, 라쏘

Linear Regression

-	손실함수 : 예측 값과 실제 값 사이 차이

Polynomail Regression

-	다항식 그래프와과 데이터 산점도를 매칭
-	차수 작고 높고 문제 -> 과대/과소적합

Rigde/Lasso
-	규제가 목적 과대적합 막기 위함

Ridge
-	MSE+ 규제 강도 조절 파라미터 값 x L2 규제 항 (가중치와 제곱값이 비례)

Lasso
-	MSE + 규제 강도 조절 파리마터 값 x L1 규제 항

L1 -> Lasso Regression
-	feature selection에 사용
-	변수 많을 때, 중요 변수만 남김
-	절대값이 선형적 증가 효과, 가중치가 0이 되는 경우로 이어지기도 함

L2 -> Ridge Regression
-	모든 feature에 다 사용, 가중치 조절 과대적합 방지
-	제곱값이 가중치 크면 더 큰 손실, 작으면 큰 변화 X
-	0에 가까워질 뿐 0이 되진 않음

분류 – 퍼셉트론 Perceptron
-	단위 계단 함수
-	이진 분류 사용, 초창기 분류 문제

SVM
-	최대 마진 찾기
-	마진 : 두 클래스 사이 간격 -> 
      최대화 하여 클래스 두개 잘 구분하는 결정 경계 만들기
-	Decision Hyperplane – 클래스 이진 분리, 3차원-평면, 2차원-선
-	최대화가 관건
-	Support vector : Decision Hyperplane 가까운 포인트

Logistic Regression

-	시그모이드 함수 값에 따라 이진분류
-	출력값은 확률 값으로 나온다.

Softmax Regression

-	편향 값을 z_k값으로 변환 시켜 함수에 대입시킨다. (선형결합형태)
-	z_k의 확률 값 반환, 모든 클래스 확률 합이 1

Decision Tree 분류

-	데이터 특성 기준/ 의사결정 규칙 만들어 분류 하는 모델
-	루트노드/ 결정노드/ 리프노드
-	Gini – 불순도 지표 – 얼마나 혼합 0이면 완벽하게 한 클래스 속함, 0.5가까우면 여러 개 혼합

Decision Tree 회귀
-	각 노드 개념 동일 
      하지만 리프노드에서 평균이나 중앙값을 최종 예측값으로 내는 차이 존재
-	데이터 여러 구간 나눠 각 구간 내에서 예측값 내기
-	MSE, 분산이 주된 지표로 사용된다.

결정트리 분류/회귀 사용시 주의해야할 점

-	Tree가 너무 깊을 때, Overfitting 주의
-	Tree가 너무 얕을 때, Underfitting 주의
-	가지 깊이 제한, 가지 일부 제거
-	앙상블 기법 적용으로 이를 방지


회귀 손실함수 – MSE, MAE, RMSE, MAPE

MAE(Mean Absolute Error, MAE) – 평균 절대 오차

<img src="formula_img\MAE.png">

-	절댓값은 예측과 정답의 차이이고 그 값을 모두 더해 평균을 낸 것
-	전체 데이터의 학습된 정도 쉽게 파악 가능
-	절댓값으로 인해 어떤 오차가 발생했는지, 음수 양수 판단 불가능

MSE(Mean Squared Error) – 평균 제곱 오차

<img src="formula_img\MSE.png">

-	i번째 학습데이터의 정답 - i번째 학습 데이터로 예측한 값들의
      총합 제곱의 평곱. 즉) 오차 제곱합의 평균.
-	가장 많이 쓰이는 손실 함수
-	제곱 연산으로 인해 차이가 커질수록 MSE 값이 뚜렷해짐,
      제곱으로 인해 오차가 양수 음수에 개의치 않고 누적 값 증가
-	제곱으로 인해 값의 왜곡 발생 ex) 1미만 값 더 작아지고, 그 이상은 더 커짐
-	MAE와 차이 최적값 근사시 이동거리가 다르게 변화 - 최적값 수렴 용이

RMSE(Root Mean Square Error, RMSE) – 평균 제곱근 오차

<img src="formula_img\RMSE.png">

-	MSE에서 값 제곱 생기는 왜곡 감소, 오차를 보다 직관적으로 나타냄
-	제곱으로 인해 1미만 에러 작아짐, 그 이상 에러는 커짐
-	실제 정답보다 낮은 예측, 높은 예측 분간이 힘듬
-	스케일 의존적 – 모델마다 에러 크기 동일해도 에어율은 동일하지 않음

MAPE(Mean Absolute Percentage Error) – 평균 절대 비율오차

<img src="formula_img\MAPE.png">

-	직관적이고 다른 모델과 에러율 비교가 쉽다
-	실제 정답 보다 낮은 예측, 높은 예측 파악이 힘들다
-	실제 정답 < 1 => 무한대 값으로 수렴
