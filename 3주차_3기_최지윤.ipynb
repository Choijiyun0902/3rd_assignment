{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPJ6bW2EqHY5S+hzxXcnVfb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Gradient Descent (경사 하강법)**\n","\n","- 머신러닝에 나온 건 확률적 경사 / 배치 / 미니배치 / 하강법\n","\n","- **함수의 값이 낮아지는 방향으로 각 독립변수들의 값을 변형시키면서 함수가 최솟값을 갖도록 하는 독립변수 값 탐색 방법**\n","\n","-최솟값 찾는 방법 = F(X)가 주어질 때 도함수가 0이 되는 지점 찾기\n"],"metadata":{"id":"7He0MWz55u7V"}},{"cell_type":"markdown","source":["# **- 경사 하강법의 문제**\n","\n","\n","**적절한 learning rate 설정**\n","- learning rate 너무 작음 = 수렴 속도 느려짐\n","- learning rate 너무 큼 = 최적점 지나 수렴하지 못할 수 있음"],"metadata":{"id":"4maFUY-LB-ZE"}},{"cell_type":"markdown","source":["**경사 하강법의 적용**\n","\n","-분류 문제에도 사용 가능"],"metadata":{"id":"Ju_0vmmNCBIy"}},{"cell_type":"markdown","source":["# ☃ ☃ ☃ ☃ ☃ ☃ ☃ ☃ ☃ ☃"],"metadata":{"id":"mT8A3NbezLB3"}},{"cell_type":"markdown","source":["# **비지도학습**\n","\n","모델이 스스로 학습하며 데이터에 숨겨진 구조를 찾도록 하는 머신러닝 기법\n","\n","\n","---\n","**1) 군집화 (k-means, Mean-Shift, DBSCAN)**\n","- 데이터 포인트 특징, 분포 파악 -> n개의 군집으로 묶음.\n","- 데이터 포인트 간의 거리, 유사도 등 특성 사용해 수행\n","- 통계 분석에 주로 사용, INSIGHT 찾을 때 좋아용\n","\n","***1-1) DBSCAN***\n","- 군집화 방식 사용, 복잡한 형태의 군집도 구분 가능\n","\n","\n","---\n","\n","\n","**2)특이치 탐지 (사기 탐지, 제조 공정 이상 탐지, 게임 핵 탐지 등 [Isolation Forest])**\n","- 데이터셋에서 일반적인 데이터 포인트들과 다른 특이한 데이터 포인트를 검출하는 알고리즘\n","\n","**2-1) Isolation Forest**\n","- 모든 포인트가 고립될 때까지 tree 생성\n","- 루트 노드와 가까운 리프노드에 위치한 데이터 포인트가 특이치\n","- 큰 data set에서 잘 작동\n","- 시각적으로 확인하기 힘든 고차원 데이터의 특이치를 검출하는데 효과적\n","\n","\n","---\n","\n","\n","**3) 생성형 작업 (GAN같은 생성형 모델 포함)**\n","- 이미지나 텍스트 생성\n","\n","\n","---\n","\n","\n","**4) 차원 축소 알고리즘**\n","- 고차원 데이터 특성을 저차원에 투영하는 알고리즘\n","- 차원의 저주 일부 해결, 효율적인 학습 가능\n","- 하지만 데이터가 갖고 있는 특성 OR 정보 잃을 수도 있으니 주의\n"],"metadata":{"id":"8SRNS1ZbCEe0"}},{"cell_type":"markdown","source":["# ☃ ☃ ☃ ☃ ☃ ☃ ☃ ☃ ☃"],"metadata":{"id":"it4otvjPzTLt"}},{"cell_type":"markdown","source":["# **준지도학습**\n","지도 학습과 비지도 학습을 결합, 레이블이 지정된 데이터와 레이블이 지정되지 않은 데이터를 모두 사용하여 분류 및 회귀 작업을 위한 인공지능 모델을 학습.\n","\n","\n","---\n","\n","\n","- 회귀보다 분류에서 많이 쓰임\n","\n","\n","---\n","\n","**준지도 학습의 가정**\n","- Smoothness Assumption : 두 데이터 포인트가 가까우면 그에 해당하는 출력도 가까울 것이다.\n","\n","- Cluster Assumption : 두 데이터 포인트가 같은 군집에 속한다면 같은 class일 것이다.\n","\n","**준지도 학습 방법론들**\n","\n","데이터에 작은 변화를 줘도 예측 결과는 같을 것이다.\n","\n","고양이 데이터에서 꼬리를 좀 자르던가 해도 고양이로 분류할 것이라고 생각하는 방법론.\n","\n","준지도는 하나만 사용하면 정확도가 좀 떨어짐. 다른 방법론과 조합해서 사용하는 게 대부분.\n"],"metadata":{"id":"gemzj695CxpX"}}]}